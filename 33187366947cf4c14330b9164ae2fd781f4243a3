{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "36cc07f5_274dc027",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1054778
      },
      "writtenOn": "2024-08-19T18:39:51Z",
      "side": 1,
      "message": "I am getting this error when running it with 8.6.2. Trying to figure out why:\n\n```\nspark-job-for-8.6.2  | org.apache.spark.SparkException: Job aborted due to stage failure: Task 11 in stage 1.0 failed 1 times, most recent failure: Lost task 11.0 in stage 1.0 (TID 25, localhost, executor driver): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Detected type name in resource [gitcommitslocalenv_2024-08-19_1724092114032/gitCommits]. Remove type name to continue.\nspark-job-for-8.6.2  | \tat org.elasticsearch.hadoop.rest.Resource.\u003cinit\u003e(Resource.java:88)\nspark-job-for-8.6.2  | \tat org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:595)\nspark-job-for-8.6.2  | \tat org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:71)\nspark-job-for-8.6.2  | \tat org.elasticsearch.spark.sql.EsSparkSQL$$anonfun$saveToEs$1.apply(EsSparkSQL.scala:103)\nspark-job-for-8.6.2  | \tat org.elasticsearch.spark.sql.EsSparkSQL$$anonfun$saveToEs$1.apply(EsSparkSQL.scala:103)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.Task.run(Task.scala:123)\nspark-job-for-8.6.2  | \tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\nspark-job-for-8.6.2  | \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\nspark-job-for-8.6.2  | \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\nspark-job-for-8.6.2  | \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\nspark-job-for-8.6.2  | \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\nspark-job-for-8.6.2  | \tat java.lang.Thread.run(Thread.java:748)\nspark-job-for-8.6.2  |\nspark-job-for-8.6.2  | Driver stacktrace:\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\nspark-job-for-8.6.2  | \tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\nspark-job-for-8.6.2  | \tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\nspark-job-for-8.6.2  | \tat scala.Option.foreach(Option.scala:257)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\nspark-job-for-8.6.2  | \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\nspark-job-for-8.6.2  | \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\nspark-job-for-8.6.2  | \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\nspark-job-for-8.6.2  | \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\nspark-job-for-8.6.2  | \tat org.elasticsearch.spark.sql.EsSparkSQL$.saveToEs(EsSparkSQL.scala:103)\nspark-job-for-8.6.2  | \tat org.elasticsearch.spark.sql.EsSparkSQL$.saveToEs(EsSparkSQL.scala:81)\nspark-job-for-8.6.2  | \tat org.elasticsearch.spark.sql.package$SparkDataFrameFunctions.saveToEs(package.scala:48)\nspark-job-for-8.6.2  | \tat com.gerritforge.analytics.infrastructure.ElasticSearchPimpedWriter.saveToEsWithAliasSwap(esSparkWriter.scala:55)\nspark-job-for-8.6.2  | \tat com.gerritforge.analytics.gitcommits.job.Job$$anonfun$saveES$1.apply(Main.scala:144)\nspark-job-for-8.6.2  | \tat com.gerritforge.analytics.gitcommits.job.Job$$anonfun$saveES$1.apply(Main.scala:142)\nspark-job-for-8.6.2  | \tat scala.Option.foreach(Option.scala:257)\nspark-job-for-8.6.2  | \tat com.gerritforge.analytics.gitcommits.job.Job$class.saveES(Main.scala:142)\nspark-job-for-8.6.2  | \tat com.gerritforge.analytics.gitcommits.job.Main$.saveES(Main.scala:33)\nspark-job-for-8.6.2  | \tat com.gerritforge.analytics.gitcommits.job.Main$.delayedEndpoint$com$gerritforge$analytics$gitcommits$job$Main$1(Main.scala:106)\nspark-job-for-8.6.2  | \tat com.gerritforge.analytics.gitcommits.job.Main$delayedInit$body.apply(Main.scala:33)\nspark-job-for-8.6.2  | \tat scala.Function0$class.apply$mcV$sp(Function0.scala:34)\nspark-job-for-8.6.2  | \tat scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)\nspark-job-for-8.6.2  | \tat scala.App$$anonfun$main$1.apply(App.scala:76)\nspark-job-for-8.6.2  | \tat scala.App$$anonfun$main$1.apply(App.scala:76)\nspark-job-for-8.6.2  | \tat scala.collection.immutable.List.foreach(List.scala:392)\nspark-job-for-8.6.2  | \tat scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:35)\nspark-job-for-8.6.2  | \tat scala.App$class.main(App.scala:76)\nspark-job-for-8.6.2  | \tat com.gerritforge.analytics.gitcommits.job.Main$.main(Main.scala:33)\nspark-job-for-8.6.2  | \tat com.gerritforge.analytics.gitcommits.job.Main.main(Main.scala)\nspark-job-for-8.6.2  | \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nspark-job-for-8.6.2  | \tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nspark-job-for-8.6.2  | \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nspark-job-for-8.6.2  | \tat java.lang.reflect.Method.invoke(Method.java:498)\nspark-job-for-8.6.2  | \tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\nspark-job-for-8.6.2  | \tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)\nspark-job-for-8.6.2  | \tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)\nspark-job-for-8.6.2  | \tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)\nspark-job-for-8.6.2  | \tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)\nspark-job-for-8.6.2  | \tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)\nspark-job-for-8.6.2  | \tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)\nspark-job-for-8.6.2  | \tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\nspark-job-for-8.6.2  | Caused by: org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Detected type name in resource [gitcommitslocalenv_2024-08-19_1724092114032/gitCommits]. Remove type name to continue.\nspark-job-for-8.6.2  | \tat org.elasticsearch.hadoop.rest.Resource.\u003cinit\u003e(Resource.java:88)\nspark-job-for-8.6.2  | \tat org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:595)\nspark-job-for-8.6.2  | \tat org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:71)\nspark-job-for-8.6.2  | \tat org.elasticsearch.spark.sql.EsSparkSQL$$anonfun$saveToEs$1.apply(EsSparkSQL.scala:103)\nspark-job-for-8.6.2  | \tat org.elasticsearch.spark.sql.EsSparkSQL$$anonfun$saveToEs$1.apply(EsSparkSQL.scala:103)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\nspark-job-for-8.6.2  | \tat org.apache.spark.scheduler.Task.run(Task.scala:123)\nspark-job-for-8.6.2  | \tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\nspark-job-for-8.6.2  | \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\nspark-job-for-8.6.2  | \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\nspark-job-for-8.6.2  | \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\nspark-job-for-8.6.2  | \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\nspark-job-for-8.6.2  | \tat java.lang.Thread.run(Thread.java:748)\n\n```",
      "revId": "33187366947cf4c14330b9164ae2fd781f4243a3",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9053c892_0f046359",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1054778
      },
      "writtenOn": "2024-08-20T15:55:50Z",
      "side": 1,
      "message": "The error is coming from the `saveToEsWithAliasSwap` which uses `elastic4s` to write on elastisearch [1].\n\nThe latest version of `elastic4s-core` compatible with scala 2.11 is 7.1.0 [2].\nThe ltest version of `elastic4s-http` compatible with scala 2.11 is 6.7.8 [3].\n\n6.7.8 is also the latest available version of `elastic4s-http` which is probably not compatible with the latest versions of Elastisearch.\n\nI will try bumping up the libraries and see what happens.\n\n[1]: https://gerrit.googlesource.com/apps/analytics-etl/+/7fcbc34b093c8cd22ef3f5537c93d0be7de7608a/common/src/main/scala/com/gerritforge/analytics/infrastructure/esSparkWriter.scala#52\n[2]: https://mvnrepository.com/artifact/com.sksamuel.elastic4s/elastic4s-core\n[3]: https://mvnrepository.com/artifact/com.sksamuel.elastic4s/elastic4s-http",
      "parentUuid": "36cc07f5_274dc027",
      "revId": "33187366947cf4c14330b9164ae2fd781f4243a3",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "32f12a3c_efc2f9b5",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1054778
      },
      "writtenOn": "2024-08-21T15:51:26Z",
      "side": 1,
      "message": "\u003e The error is coming from the saveToEsWithAliasSwap which uses elastic4s to write on elastisearch 1.\n\nScratch that. I managed to pass that error. It was question of setting \"--conf spark.es.nodes.wan.only\u003dtrue\". No idea why it wasn\u0027t needed in previous versions.\n\nHowever, now I am facing another error which I believe is linked to `elastic4s`:\n\n```\nspark-job-for-8.6.2  | com.sksamuel.elastic4s.http.JavaClientExceptionWrapper: java.lang.NullPointerException\nspark-job-for-8.6.2  | \tat com.sksamuel.elastic4s.http.ElasticsearchJavaRestClient$$anon$1.onFailure(ElasticsearchJavaRestClient.scala:63)\nspark-job-for-8.6.2  | \tat org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onDefinitiveFailure(RestClient.java:850)\nspark-job-for-8.6.2  | \tat org.elasticsearch.client.RestClient$1.completed(RestClient.java:558)\nspark-job-for-8.6.2  | \tat org.elasticsearch.client.RestClient$1.completed(RestClient.java:531)\nspark-job-for-8.6.2  | \tat org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:123)\nspark-job-for-8.6.2  | \tat org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:177)\nspark-job-for-8.6.2  | \tat org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:436)\nspark-job-for-8.6.2  | \tat org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:326)\nspark-job-for-8.6.2  | \tat org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)\nspark-job-for-8.6.2  | \tat org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)\nspark-job-for-8.6.2  | \tat org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)\nspark-job-for-8.6.2  | \tat org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)\nspark-job-for-8.6.2  | \tat org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)\nspark-job-for-8.6.2  | \tat org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)\nspark-job-for-8.6.2  | \tat org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)\nspark-job-for-8.6.2  | \tat org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)\nspark-job-for-8.6.2  | \tat org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)\nspark-job-for-8.6.2  | \tat org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:588)\nspark-job-for-8.6.2  | \tat java.lang.Thread.run(Thread.java:748)\nspark-job-for-8.6.2  | Caused by: java.lang.NullPointerException\nspark-job-for-8.6.2  | \tat scala.io.Codec.decoder(Codec.scala:61)\nspark-job-for-8.6.2  | \tat scala.io.BufferedSource.reader(BufferedSource.scala:24)\nspark-job-for-8.6.2  | \tat scala.io.BufferedSource.bufferedReader(BufferedSource.scala:25)\nspark-job-for-8.6.2  | \tat scala.io.BufferedSource.scala$io$BufferedSource$$charReader$lzycompute(BufferedSource.scala:35)\nspark-job-for-8.6.2  | \tat scala.io.BufferedSource.scala$io$BufferedSource$$charReader(BufferedSource.scala:33)\nspark-job-for-8.6.2  | \tat scala.io.BufferedSource.scala$io$BufferedSource$$decachedReader(BufferedSource.scala:62)\nspark-job-for-8.6.2  | \tat scala.io.BufferedSource.mkString(BufferedSource.scala:91)\nspark-job-for-8.6.2  | \tat com.sksamuel.elastic4s.http.ElasticsearchJavaRestClient$$anonfun$1.apply(ElasticsearchJavaRestClient.scala:44)\nspark-job-for-8.6.2  | \tat com.sksamuel.elastic4s.http.ElasticsearchJavaRestClient$$anonfun$1.apply(ElasticsearchJavaRestClient.scala:35)\nspark-job-for-8.6.2  | \tat scala.Option.map(Option.scala:146)\nspark-job-for-8.6.2  | \tat com.sksamuel.elastic4s.http.ElasticsearchJavaRestClient.fromResponse(ElasticsearchJavaRestClient.scala:35)\nspark-job-for-8.6.2  | \tat com.sksamuel.elastic4s.http.ElasticsearchJavaRestClient$$anon$1.onSuccess(ElasticsearchJavaRestClient.scala:60)\nspark-job-for-8.6.2  | \tat org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:842)\nspark-job-for-8.6.2  | \tat org.elasticsearch.client.RestClient$1.completed(RestClient.java:543)\nspark-job-for-8.6.2  | \t... 16 more\n```",
      "parentUuid": "9053c892_0f046359",
      "revId": "33187366947cf4c14330b9164ae2fd781f4243a3",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "3e85bbff_3394a9d9",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2024-08-26T09:45:06Z",
      "side": 1,
      "message": "That is now resolved in master, as we don\u0027t use elastic4s anymore.",
      "parentUuid": "32f12a3c_efc2f9b5",
      "revId": "33187366947cf4c14330b9164ae2fd781f4243a3",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7ca29317_938a111d",
        "filename": "project/SharedSettings.scala",
        "patchSetId": 1
      },
      "lineNbr": 113,
      "author": {
        "id": 1054778
      },
      "writtenOn": "2024-08-20T14:49:09Z",
      "side": 1,
      "message": "Different version of the client relies on different documents structure. In the code we are currently using the document type in the resource [1] which is not supported from ES 7.x.\n\nIf document type was NOT mandatory in 6.X we can just remove it.\n\nOtheriwse, instead of injecting the version from a varaible I think we should branch the repo if we want to maintain different versions.\n\n[1]: https://gerrit.googlesource.com/apps/analytics-etl/+/7fcbc34b093c8cd22ef3f5537c93d0be7de7608a/common/src/main/scala/com/gerritforge/analytics/infrastructure/esSparkWriter.scala#44",
      "range": {
        "startLine": 113,
        "startChar": 100,
        "endLine": 113,
        "endChar": 105
      },
      "revId": "33187366947cf4c14330b9164ae2fd781f4243a3",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "6d0fe9e9_c05f0b9b",
        "filename": "project/SharedSettings.scala",
        "patchSetId": 1
      },
      "lineNbr": 113,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2024-08-26T09:45:06Z",
      "side": 1,
      "message": "This is now resolved as we don\u0027t assume anymore the structure of the index type.",
      "parentUuid": "7ca29317_938a111d",
      "range": {
        "startLine": 113,
        "startChar": 100,
        "endLine": 113,
        "endChar": 105
      },
      "revId": "33187366947cf4c14330b9164ae2fd781f4243a3",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    }
  ]
}